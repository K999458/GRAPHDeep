{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import module\n",
    "import stlearn as st\n",
    "from pathlib import Path\n",
    "st.settings.set_figure_params(dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sq.datasets.slideseqv2() # 4000高变基因\n",
    "data.var_names_make_unique() \n",
    "data = data[(data.obs[\"x\"]>=1000) & (data.obs[\"x\"]<=5600) & (data.obs[\"y\"]<=5400) & (data.obs[\"y\"]>=2600)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 26146 × 4000\n",
       "    obs: 'barcode', 'x', 'y', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_MT', 'log1p_total_counts_MT', 'pct_counts_MT', 'n_counts', 'leiden', 'cluster'\n",
       "    var: 'MT', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'cluster_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'spatial_neighbors', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap', 'deconvolution_results', 'spatial'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances', 'spatial_connectivities', 'spatial_distances'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization step is finished in adata.X\n",
      "Log transformation step is finished in adata.X\n"
     ]
    }
   ],
   "source": [
    "st.pp.filter_genes(data,min_cells=1)\n",
    "st.pp.normalize_total(data)\n",
    "st.pp.log1p(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 26146 × 4000\n",
       "    obs: 'barcode', 'x', 'y', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_MT', 'log1p_total_counts_MT', 'pct_counts_MT', 'n_counts', 'leiden', 'cluster'\n",
       "    var: 'MT', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'cluster_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'spatial_neighbors', 'umap', 'log1p'\n",
       "    obsm: 'X_pca', 'X_umap', 'deconvolution_results', 'spatial'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances', 'spatial_connectivities', 'spatial_distances'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA is done! Generated in adata.obsm['X_pca'], adata.uns['pca'] and adata.varm['PCs']\n"
     ]
    }
   ],
   "source": [
    "# run PCA for gene expression data\n",
    "st.em.run_pca(data,n_comps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'imagerow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'imagerow'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m data_SME \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m \u001b[39m# apply stSME to normalise log transformed data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m st\u001b[39m.\u001b[39mspatial\u001b[39m.\u001b[39mSME\u001b[39m.\u001b[39mSME_normalize(data_SME, use_data\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m data_SME\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m data_SME\u001b[39m.\u001b[39mobsm[\u001b[39m'\u001b[39m\u001b[39mraw_SME_normalized\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m st\u001b[39m.\u001b[39mpp\u001b[39m.\u001b[39mscale(data_SME)\n",
      "File \u001b[0;32m~/miniconda3/envs/Torch_pyG/lib/python3.8/site-packages/stlearn/spatials/SME/normalize.py:60\u001b[0m, in \u001b[0;36mSME_normalize\u001b[0;34m(adata, use_data, weights, platform, copy)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     count_embed \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39mobsm[use_data]\n\u001b[0;32m---> 60\u001b[0m calculate_weight_matrix(adata, platform\u001b[39m=\u001b[39;49mplatform)\n\u001b[1;32m     62\u001b[0m impute_neighbour(adata, count_embed\u001b[39m=\u001b[39mcount_embed, weights\u001b[39m=\u001b[39mweights)\n\u001b[1;32m     64\u001b[0m imputed_data \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39mobsm[\u001b[39m\"\u001b[39m\u001b[39mimputed_data\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Torch_pyG/lib/python3.8/site-packages/stlearn/spatials/SME/_weighting_matrix.py:30\u001b[0m, in \u001b[0;36mcalculate_weight_matrix\u001b[0;34m(adata, adata_imputed, pseudo_spots, platform)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m platform \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mVisium\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     img_row \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39;49mobs[\u001b[39m\"\u001b[39;49m\u001b[39mimagerow\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     31\u001b[0m     img_col \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39mobs[\u001b[39m\"\u001b[39m\u001b[39mimagecol\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     32\u001b[0m     array_row \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39mobs[\u001b[39m\"\u001b[39m\u001b[39marray_row\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'imagerow'"
     ]
    }
   ],
   "source": [
    "data_SME = data.copy()\n",
    "# apply stSME to normalise log transformed data\n",
    "st.spatial.SME.SME_normalize(data_SME, use_data=\"raw\")\n",
    "data_SME.X = data_SME.obsm['raw_SME_normalized']\n",
    "st.pp.scale(data_SME)\n",
    "st.em.run_pca(data_SME,n_comps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing for spot image\n",
    "st.pp.tiling(data, TILE_PATH)\n",
    "\n",
    "# this step uses deep learning model to extract high-level features from tile images\n",
    "# may need few minutes to be completed\n",
    "st.pp.extract_feature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanpy import read_10x_h5\n",
    "\n",
    "# proj_list = ['151507']\n",
    "ARI_list,AMI_list = [],[]\n",
    "\n",
    "# adata = sq.datasets.slideseqv2() # 4000高变基因\n",
    "# adata.var_names_make_unique() \n",
    "# adata = adata[(adata.obs[\"x\"]>=1000) & (adata.obs[\"x\"]<=5600) & (adata.obs[\"y\"]<=5400) & (adata.obs[\"y\"]>=2600)]\n",
    "adata = read_10x_h5(\"/home/tengliu/Torch_pyG/Breast_cancer_comparison/SPGDL/data/V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5\")\n",
    "spatial=pd.read_csv(\"/home/tengliu/Torch_pyG/Breast_cancer_comparison/SPGDL/data/spatial/tissue_positions_list.csv\",sep=\",\",header=None,na_filter=False,index_col=0) \n",
    "\n",
    "adata.obs[\"x1\"]=spatial[1]\n",
    "adata.obs[\"x2\"]=spatial[2]\n",
    "adata.obs[\"x3\"]=spatial[3]\n",
    "adata.obs[\"x4\"]=spatial[4]\n",
    "adata.obs[\"x5\"]=spatial[5]\n",
    "adata.obs[\"x_array\"]=adata.obs[\"x2\"]\n",
    "adata.obs[\"y_array\"]=adata.obs[\"x3\"]\n",
    "adata.obs[\"x_pixel\"]=adata.obs[\"x4\"]\n",
    "adata.obs[\"y_pixel\"]=adata.obs[\"x5\"]\n",
    "#Select captured samples\n",
    "adata=adata[adata.obs[\"x1\"]==1]\n",
    "adata.var_names=[i.upper() for i in list(adata.var_names)]\n",
    "adata.var[\"genename\"]=adata.var.index.astype(\"str\")\n",
    "img=cv2.imread(\"/home/tengliu/Torch_pyG/Breast_cancer_comparison/SPGDL/data/V1_Breast_Cancer_Block_A_Section_1_image.tif\")\n",
    "#Set coordinates\n",
    "x_array=adata.obs[\"x_array\"].tolist()\n",
    "y_array=adata.obs[\"y_array\"].tolist()\n",
    "x_pixel=adata.obs[\"x_pixel\"].tolist()\n",
    "y_pixel=adata.obs[\"y_pixel\"].tolist()\n",
    "\n",
    "#Test coordinates on the image\n",
    "img_new=img.copy()\n",
    "for i in range(len(x_pixel)):\n",
    "    x=x_pixel[i]\n",
    "    y=y_pixel[i]\n",
    "    img_new[int(x-20):int(x+20), int(y-20):int(y+20),:]=0\n",
    "\n",
    "#Calculate adjacent matrix\n",
    "s=1\n",
    "b=49\n",
    "adj=spg.calculate_adj_matrix(x=x_pixel,y=y_pixel, x_pixel=x_pixel, y_pixel=y_pixel, image=img, beta=b, alpha=s, histology=True)\n",
    "#If histlogy image is not available, SpaGCN can calculate the adjacent matrix using the fnction below\n",
    "#adj=calculate_adj_matrix(x=x_pixel,y=y_pixel, histology=False)\n",
    "\n",
    "#Normalization\n",
    "adata.var_names_make_unique()\n",
    "spg.prefilter_genes(adata,min_cells=3) # avoiding all genes are zeros\n",
    "spg.prefilter_specialgenes(adata)\n",
    "#Normalize and take log for UMI\n",
    "sc.pp.normalize_per_cell(adata)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "p=0.5 \n",
    "#Find the l value given p\n",
    "l=spg.search_l(p, adj, start=0.01, end=1000, tol=0.01, max_run=100)\n",
    "\n",
    "\n",
    "n_clusters = 20\n",
    "#Set seed\n",
    "r_seed=t_seed=n_seed=100\n",
    "#Seaech for suitable resolution\n",
    "res=spg.search_res(adata, adj, l, n_clusters, start=0.7, step=0.1, tol=5e-3, lr=0.05, max_epochs=20, r_seed=r_seed, t_seed=t_seed, n_seed=n_seed)\n",
    "\n",
    "clf=spg.SpaGCN()\n",
    "clf.set_l(l)\n",
    "#Set seed\n",
    "random.seed(r_seed)\n",
    "torch.manual_seed(t_seed)\n",
    "np.random.seed(n_seed)\n",
    "#Run\n",
    "clf.train(adata,adj,init_spa=True,init=\"louvain\",res=res, tol=5e-3, lr=0.05, max_epochs=200)\n",
    "y_pred, prob=clf.predict()\n",
    "adata.obs[\"pred\"]= y_pred\n",
    "adata.obs[\"pred\"]=adata.obs[\"pred\"].astype('category')\n",
    "\n",
    "# load ground truth read the annotation  \n",
    "df_meta = pd.read_csv('/home/tengliu/Torch_pyG/Breast_cancer_comparison/SPGDL/data/metadata.tsv', sep='\\t',index_col=0)\n",
    "# index_col = 0 能够去掉dataframe最左边的序号列。\n",
    "df_meta = df_meta.drop(columns=['annot_type'])\n",
    "df_meta.columns = ['Ground Truth']\n",
    "adata.obs['Ground Truth'] = df_meta.loc[adata.obs_names, 'Ground Truth']\n",
    "\n",
    "from sklearn import metrics\n",
    "obs_df = adata.obs.dropna() ##过滤掉缺失值的行，即当前分类值为Nan，就把该行过滤掉。\n",
    "ARI = metrics.adjusted_rand_score(obs_df['pred'], obs_df['Ground Truth']) ## ARI 是从 包sklearn.metrics.cluster中导入的衡量标准\n",
    "AMI = metrics.adjusted_mutual_info_score(obs_df['pred'], obs_df['Ground Truth'])\n",
    "\n",
    "print('Adjusted rand index = %.2f' %ARI)\n",
    "adata.uns[\"ARI\"] = ARI\n",
    "adata.uns[\"AMI\"] = AMI\n",
    "\n",
    "ARI_list.append(ARI)\n",
    "AMI_list.append(AMI)\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.pca(adata,n_comps=30)\n",
    "sc.pp.neighbors(adata)\n",
    "# sc.pp.neighbors(adata, use_rep='STAGATE',n_neighbors=250,n_pcs=30,knn=True,method=\"umap\") \n",
    "# ## STAGATE为训练出来的embeddings, 然后用它进行下游的分析。\n",
    "sc.tl.umap(adata) ## 利用neighbors计算降维图Umap.\n",
    "\n",
    "adata_filename = \"Human_Cancer\"+\"_spaGCN\"+\".h5ad\"\n",
    "adata.filename = './Results/'+adata_filename\n",
    "\n",
    "Metrics_spaGCN = pd.DataFrame([ARI_list,AMI_list])\n",
    "Metrics_spaGCN.to_csv(\"./Results/Metrics_spaGCN .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (4, 4)\n",
    "sc.pl.umap(adata, color=['pred', \"Ground Truth\"],legend_loc='on data', \n",
    "            legend_fontsize=12,legend_fontoutline=2,frameon=False, title=['pred' + ' (ARI=%.2f)'%ARI, \"Ground Truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Torch_pyG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6c5b14914244c672f1ff2231c12cd4f84e9de6a7a49ed2347547bb7be8e01f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
